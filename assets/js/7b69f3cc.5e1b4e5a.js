"use strict";(self.webpackChunkdocu=self.webpackChunkdocu||[]).push([[7867],{3905:function(e,t,n){n.d(t,{Zo:function(){return s},kt:function(){return k}});var i=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,r=function(e,t){if(null==e)return{};var n,i,r={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=i.createContext({}),c=function(e){var t=i.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},s=function(e){var t=c(e.components);return i.createElement(d.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},p=i.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,d=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),p=c(n),k=r,m=p["".concat(d,".").concat(k)]||p[k]||u[k]||o;return n?i.createElement(m,a(a({ref:t},s),{},{components:n})):i.createElement(m,a({ref:t},s))}));function k(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,a=new Array(o);a[0]=p;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l.mdxType="string"==typeof e?e:r,a[1]=l;for(var c=2;c<o;c++)a[c]=n[c];return i.createElement.apply(null,a)}return i.createElement.apply(null,n)}p.displayName="MDXCreateElement"},68871:function(e,t,n){n.r(t),n.d(t,{assets:function(){return s},contentTitle:function(){return d},default:function(){return k},frontMatter:function(){return l},metadata:function(){return c},toc:function(){return u}});var i=n(87462),r=n(63366),o=(n(67294),n(3905)),a=["components"],l={},d="Developing on docker",c={unversionedId:"contributing-to-airbyte/developing-on-docker",id:"contributing-to-airbyte/developing-on-docker",title:"Developing on docker",description:"Incrementality",source:"@site/../docs/contributing-to-airbyte/developing-on-docker.md",sourceDirName:"contributing-to-airbyte",slug:"/contributing-to-airbyte/developing-on-docker",permalink:"/contributing-to-airbyte/developing-on-docker",editUrl:"https://github.com/airbytehq/airbyte/docs/../docs/contributing-to-airbyte/developing-on-docker.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"Developing Locally",permalink:"/contributing-to-airbyte/developing-locally"},next:{title:"Developing on Kubernetes",permalink:"/contributing-to-airbyte/developing-on-kubernetes"}},s={},u=[{value:"Incrementality",id:"incrementality",level:2},{value:"Adding a new docker build",id:"adding-a-new-docker-build",level:2},{value:"Building the docker images",id:"building-the-docker-images",level:2},{value:"Handling the OSS version",id:"handling-the-oss-version",level:2},{value:"Existing modules",id:"existing-modules",level:3},{value:"New module",id:"new-module",level:3}],p={toc:u};function k(e){var t=e.components,n=(0,r.Z)(e,a);return(0,o.kt)("wrapper",(0,i.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"developing-on-docker"},"Developing on docker"),(0,o.kt)("h2",{id:"incrementality"},"Incrementality"),(0,o.kt)("p",null,"The docker build is fully incremental for the platform build, which means that it will only build an image if it is needed. We need to keep it that\nway.\nA task generator, ",(0,o.kt)("inlineCode",{parentName:"p"},"getDockerBuildTask"),", is available for building a docker image for any given module. Behind the scene, it will generate a\ntask which will run the build of a docker image in a specific folder. The goal is to make sure that we have an isolated\ncontext which helps with incrementality. All files that need to be present in the docker image will need to be copy into this folder. The generate\nmethod takes 2 arguments:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The image name, for example if ",(0,o.kt)("inlineCode",{parentName:"li"},"foo")," is given as an image name, the image ",(0,o.kt)("inlineCode",{parentName:"li"},"airbyte/foo")," will be created"),(0,o.kt)("li",{parentName:"ul"},"The project directory folder. It is needed because the ",(0,o.kt)("inlineCode",{parentName:"li"},"getDockerBuildTask")," is declared in the rootProject")),(0,o.kt)("h2",{id:"adding-a-new-docker-build"},"Adding a new docker build"),(0,o.kt)("p",null,"Once you have a ",(0,o.kt)("inlineCode",{parentName:"p"},"Dockerfile"),", generating the docker image is done in the following way:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"specify the artifact name, the project directory, the version, and the tag."),(0,o.kt)("li",{parentName:"ul"},"make sure that the Dockerfile is properly copied to the docker context dir before building the image"),(0,o.kt)("li",{parentName:"ul"},"make the build docker task to depend on the ",(0,o.kt)("inlineCode",{parentName:"li"},"assemble")," task.")),(0,o.kt)("p",null,"For example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-groovy"},'Task dockerBuildTask = getDockerBuildTask("cli", project.projectDir, rootProject.ext.version, rootProject.ext.image_tag)\ndockerBuildTask.dependsOn(copyDocker)\nassemble.dependsOn(dockerBuildTask)\n')),(0,o.kt)("p",null,"If you need to add files in your image you need to copy them in ",(0,o.kt)("inlineCode",{parentName:"p"},"build/docker/bin")," first. The need to happen after the ",(0,o.kt)("inlineCode",{parentName:"p"},"copyDocker")," task.\nThe ",(0,o.kt)("inlineCode",{parentName:"p"},"copyDocker")," task clean up the ",(0,o.kt)("inlineCode",{parentName:"p"},"build/docker")," folder as a first step."),(0,o.kt)("p",null,"For example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-groovy"},"task copyScripts(type: Copy) {\n    dependsOn copyDocker\n\n    from('scripts')\n    into 'build/docker/bin/scripts'\n}\n\nTask dockerBuildTask = getDockerBuildTask(\"init\", project.projectDir, rootProject.ext.version, rootProject.ext.image_tag)\ndockerBuildTask.dependsOn(copyScripts)\nassemble.dependsOn(dockerBuildTask)\n")),(0,o.kt)("h2",{id:"building-the-docker-images"},"Building the docker images"),(0,o.kt)("p",null,"The gradle task ",(0,o.kt)("inlineCode",{parentName:"p"},"generate-docker")," allows to build all the docker images."),(0,o.kt)("h2",{id:"handling-the-oss-version"},"Handling the OSS version"),(0,o.kt)("p",null,"The docker images that are running using a jar need to the latest published OSS version on master. Here is how it is handle:"),(0,o.kt)("h3",{id:"existing-modules"},"Existing modules"),(0,o.kt)("p",null,"The version should already be present. If a new version is published while a PR is open, it should generate a conflict, that will prevent you from\nmerging the review. There are scenarios where it is going to generate and error (The Dockerfile is moved for example), the way to avoid any issue\nis to:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Check the ",(0,o.kt)("inlineCode",{parentName:"li"},".env")," file to make sure that the latest version align with the version in the PR"),(0,o.kt)("li",{parentName:"ul"},"Merge the ",(0,o.kt)("inlineCode",{parentName:"li"},"master")," branch in the PR and make sure that the build is working right before merging.")),(0,o.kt)("p",null,"If the version don't align, it will break the remote ",(0,o.kt)("inlineCode",{parentName:"p"},"master")," build."),(0,o.kt)("p",null,"The version will be automatically replace with new version when releasing the OSS version using the ",(0,o.kt)("inlineCode",{parentName:"p"},".bumpversion.cfg"),"."),(0,o.kt)("h3",{id:"new-module"},"New module"),(0,o.kt)("p",null,"This is trickier than handling the version of an exiting module.\nFirst your docker file generating an image need to be added to the ",(0,o.kt)("inlineCode",{parentName:"p"},".bumpversion.cfg"),". For each and every version you want to build with, the\ndocker image will need to be manually tag and push until the PR is merge. The reason is that the build has a check to know if all the potential\ndocker images are present in the docker repository. It is done the following way:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"docker tag 7d94ea2ad657 airbyte/temporal:0.30.35-alpha\ndocker push airbyte/temporal:0.30.35-alpha\n")),(0,o.kt)("p",null,"The image ID can be retrieved using ",(0,o.kt)("inlineCode",{parentName:"p"},"docker images")," or the docker desktop UI."))}k.isMDXComponent=!0}}]);